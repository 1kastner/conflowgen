{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f203daff-80ec-472a-a47c-801e6a2999fe",
   "metadata": {},
   "source": [
    "# Visuals for LDIC2022 Paper\n",
    "\n",
    "Here, the visuals for the publication are created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dbfba7-1647-4644-b16a-2749f57e4c55",
   "metadata": {},
   "source": [
    "Import standard libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ce902-7b1b-4941-b7a5-bb772575035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard libraries\n",
    "import os\n",
    "import string\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# scientific standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches as mpatches\n",
    "from matplotlib import dates as mdates\n",
    "\n",
    "# Jupyter notebook-related libraries\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133e8e7-7c98-40d5-9c7f-db6fe6ef6bb2",
   "metadata": {},
   "source": [
    "Import conflowgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ca55f-1cda-407b-8fe3-ab73c1688110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conflowgen import ContainerFlowGenerationManager\n",
    "from conflowgen import ModeOfTransport\n",
    "from conflowgen import PortCallManager\n",
    "from conflowgen import ExportFileFormat\n",
    "from conflowgen import ExportContainerFlowManager\n",
    "from conflowgen import DatabaseChooser\n",
    "from conflowgen import setup_logger\n",
    "from conflowgen import InboundAndOutboundVehicleCapacityPreviewReport\n",
    "from conflowgen import ContainerFlowByVehicleTypePreviewReport\n",
    "from conflowgen import VehicleCapacityExceededPreviewReport\n",
    "from conflowgen import ModalSplitPreviewReport\n",
    "from conflowgen import InboundAndOutboundVehicleCapacityAnalysisReport\n",
    "from conflowgen import ContainerFlowByVehicleTypeAnalysisReport\n",
    "from conflowgen import ModalSplitAnalysisReport\n",
    "from conflowgen import ContainerFlowAdjustmentByVehicleTypeAnalysisReport\n",
    "from conflowgen import ContainerFlowAdjustmentByVehicleTypeAnalysisSummaryReport\n",
    "from conflowgen import ContainerLengthDistributionManager\n",
    "from conflowgen import ContainerLength\n",
    "from conflowgen import ModeOfTransportDistributionManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886731a-bc83-44ce-bc68-a422b9211e44",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "Now, conflowgen is initialized with the schedules.\n",
    "This is based on the script `demo_DEHAM_CTA.py` but is shortened.\n",
    "Some logging messages and some comments have been removed for brevity.\n",
    "For further information, turn to `demo_DEHAM_CTA.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a0965-2579-4727-a7d1-05a997ef8c20",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import conflowgen\n",
    "\n",
    "seeded_random = random.Random(x=1)\n",
    "\n",
    "import_root_dir = os.path.abspath(\n",
    "    os.path.join(\n",
    "        os.path.dirname(conflowgen.__path__[0]),\n",
    "        \"demo\",\n",
    "        \"data\"\n",
    "    )\n",
    ")\n",
    "import_deham_dir = os.path.join(\n",
    "    import_root_dir,\n",
    "    \"DEHAM\",\n",
    "    \"CT Altenwerder\"\n",
    ")\n",
    "df_deep_sea_vessels = pd.read_csv(\n",
    "    os.path.join(\n",
    "        import_deham_dir,\n",
    "        \"deep_sea_vessel_input.csv\"\n",
    "    ),\n",
    "    index_col=[0]\n",
    ")\n",
    "df_feeders = pd.read_csv(\n",
    "    os.path.join(\n",
    "        import_deham_dir,\n",
    "        \"feeder_input.csv\"\n",
    "    ),\n",
    "    index_col=[0]\n",
    ")\n",
    "df_barges = pd.read_csv(\n",
    "    os.path.join(\n",
    "        import_deham_dir,\n",
    "        \"barge_input.csv\"\n",
    "    ),\n",
    "    index_col=[0]\n",
    ")\n",
    "df_trains = pd.read_csv(\n",
    "    os.path.join(\n",
    "        import_deham_dir,\n",
    "        \"train_input.csv\"\n",
    "    ),\n",
    "    index_col=[0]\n",
    ")\n",
    "\n",
    "logger = setup_logger()\n",
    "database_chooser = DatabaseChooser()\n",
    "\n",
    "\n",
    "def initialize_conflowgen(figure_name: str, force_reload=False) -> ContainerFlowGenerationManager:\n",
    "    demo_file_name = f\"demo_deham_cta_visual_{figure_name}.sqlite\"\n",
    "\n",
    "    if demo_file_name in database_chooser.list_all_sqlite_databases():\n",
    "        database_chooser.load_existing_sqlite_database(demo_file_name)\n",
    "        if not force_reload:\n",
    "            container_flow_generation_manager = ContainerFlowGenerationManager()\n",
    "            return container_flow_generation_manager\n",
    "    else:\n",
    "        database_chooser.create_new_sqlite_database(demo_file_name)\n",
    "\n",
    "    container_flow_generation_manager = ContainerFlowGenerationManager()\n",
    "    container_flow_start_date = datetime.date(year=2021, month=7, day=1)\n",
    "    container_flow_end_date = datetime.date(year=2021, month=7, day=31)\n",
    "    container_flow_generation_manager.set_properties(\n",
    "        name=\"Demo DEHAM CTA Visual 1a\",\n",
    "        start_date=container_flow_start_date,\n",
    "        end_date=container_flow_end_date\n",
    "    )\n",
    "    port_call_manager = PortCallManager()\n",
    "    for i, row in df_feeders.iterrows():\n",
    "        feeder_vehicle_name = row[\"vehicle_name\"] + \"-unique\"\n",
    "        capacity = row[\"capacity\"]\n",
    "        vessel_arrives_at_as_pandas_type = row[\"arrival (planned)\"]\n",
    "        vessel_arrives_at_as_datetime_type = pd.to_datetime(vessel_arrives_at_as_pandas_type)\n",
    "\n",
    "        if vessel_arrives_at_as_datetime_type.date() < container_flow_start_date:\n",
    "            logger.info(f\"Skipping feeder '{feeder_vehicle_name}' because it arrives before the start\")\n",
    "            continue\n",
    "\n",
    "        if vessel_arrives_at_as_datetime_type.date() > container_flow_end_date:\n",
    "            logger.info(f\"Skipping feeder '{feeder_vehicle_name}' because it arrives after the end\")\n",
    "            continue\n",
    "\n",
    "        if port_call_manager.get_schedule(feeder_vehicle_name, vehicle_type=ModeOfTransport.feeder):\n",
    "            logger.info(f\"Skipping feeder '{feeder_vehicle_name}' because it already exists\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Add feeder '{feeder_vehicle_name}' to database\")\n",
    "        moved_capacity = int(round(capacity * seeded_random.uniform(0.3, 0.8) / 2))\n",
    "        port_call_manager.add_large_scheduled_vehicle(\n",
    "            vehicle_type=ModeOfTransport.feeder,\n",
    "            service_name=feeder_vehicle_name,\n",
    "            vehicle_arrives_at=vessel_arrives_at_as_datetime_type.date(),\n",
    "            vehicle_arrives_at_time=vessel_arrives_at_as_datetime_type.time(),\n",
    "            average_vehicle_capacity=capacity,\n",
    "            average_moved_capacity=moved_capacity,\n",
    "            vehicle_arrives_every_k_days=-1\n",
    "        )\n",
    "\n",
    "    logger.info(\"Start importing deep sea vessels...\")\n",
    "    for i, row in df_deep_sea_vessels.iterrows():\n",
    "        deep_sea_vessel_vehicle_name = row[\"vehicle_name\"] + \"-unique\"\n",
    "        capacity = row[\"capacity\"]\n",
    "        vessel_arrives_at_as_pandas_type = row[\"arrival (planned)\"]\n",
    "        vessel_arrives_at_as_datetime_type = pd.to_datetime(vessel_arrives_at_as_pandas_type)\n",
    "\n",
    "        if vessel_arrives_at_as_datetime_type.date() < container_flow_start_date:\n",
    "            logger.info(f\"Skipping deep sea vessel '{deep_sea_vessel_vehicle_name}' because it arrives before the start\")\n",
    "            continue\n",
    "\n",
    "        if vessel_arrives_at_as_datetime_type.date() > container_flow_end_date:\n",
    "            logger.info(f\"Skipping deep sea vessel '{deep_sea_vessel_vehicle_name}' because it arrives after the end\")\n",
    "            continue\n",
    "\n",
    "        if port_call_manager.get_schedule(deep_sea_vessel_vehicle_name, vehicle_type=ModeOfTransport.deep_sea_vessel):\n",
    "            logger.info(f\"Skipping deep sea service '{deep_sea_vessel_vehicle_name}' because it already exists\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Add deep sea vessel '{deep_sea_vessel_vehicle_name}' to database\")\n",
    "        moved_capacity = int(round(capacity * seeded_random.uniform(0.25, 0.5) / 2))\n",
    "        port_call_manager.add_large_scheduled_vehicle(\n",
    "            vehicle_type=ModeOfTransport.deep_sea_vessel,\n",
    "            service_name=deep_sea_vessel_vehicle_name,\n",
    "            vehicle_arrives_at=vessel_arrives_at_as_datetime_type.date(),\n",
    "            vehicle_arrives_at_time=vessel_arrives_at_as_datetime_type.time(),\n",
    "            average_vehicle_capacity=capacity,\n",
    "            average_moved_capacity=moved_capacity,\n",
    "            vehicle_arrives_every_k_days=-1\n",
    "        )\n",
    "\n",
    "    logger.info(\"Start importing barges...\")\n",
    "    for i, row in df_barges.iterrows():\n",
    "        barge_vehicle_name = row[\"vehicle_name\"] + \"-unique\"\n",
    "        capacity = row[\"capacity\"]\n",
    "        vessel_arrives_at_as_pandas_type = row[\"arrival (planned)\"]\n",
    "        vessel_arrives_at_as_datetime_type = pd.to_datetime(vessel_arrives_at_as_pandas_type)\n",
    "\n",
    "        if vessel_arrives_at_as_datetime_type.date() < container_flow_start_date:\n",
    "            logger.info(f\"Skipping barge '{barge_vehicle_name}' because it arrives before the start\")\n",
    "            continue\n",
    "\n",
    "        if vessel_arrives_at_as_datetime_type.date() > container_flow_end_date:\n",
    "            logger.info(f\"Skipping barge '{barge_vehicle_name}' because it arrives after the end\")\n",
    "            continue\n",
    "\n",
    "        if port_call_manager.get_schedule(barge_vehicle_name, vehicle_type=ModeOfTransport.barge):\n",
    "            logger.info(f\"Skipping barge '{barge_vehicle_name}' because it already exists\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Add barge '{barge_vehicle_name}' to database\")\n",
    "        moved_capacity = int(round(capacity * seeded_random.uniform(0.3, 0.6)))\n",
    "        port_call_manager.add_large_scheduled_vehicle(\n",
    "            vehicle_type=ModeOfTransport.barge,\n",
    "            service_name=barge_vehicle_name,\n",
    "            vehicle_arrives_at=vessel_arrives_at_as_datetime_type.date(),\n",
    "            vehicle_arrives_at_time=vessel_arrives_at_as_datetime_type.time(),\n",
    "            average_vehicle_capacity=capacity,\n",
    "            average_moved_capacity=moved_capacity,\n",
    "            vehicle_arrives_every_k_days=-1\n",
    "        )\n",
    "\n",
    "    logger.info(\"Start importing trains...\")\n",
    "    for i, row in df_trains.iterrows():\n",
    "        train_vehicle_name = row[\"vehicle_name\"]\n",
    "        vessel_arrives_at_as_pandas_type = row[\"arrival_day\"]\n",
    "        vessel_arrives_at_as_datetime_type = pd.to_datetime(vessel_arrives_at_as_pandas_type)\n",
    "\n",
    "        if port_call_manager.get_schedule(train_vehicle_name, vehicle_type=ModeOfTransport.train):\n",
    "            logger.info(f\"Train service '{train_vehicle_name}' already exists\")\n",
    "            continue\n",
    "\n",
    "        capacity = 96  # in TEU, see https://www.intermodal-info.com/verkehrstraeger/\n",
    "        earliest_time = datetime.time(hour=1, minute=0)\n",
    "        earliest_time_as_delta = datetime.timedelta(hours=earliest_time.hour, minutes=earliest_time.minute)\n",
    "        latest_time = datetime.time(hour=5, minute=30)\n",
    "        latest_time_as_delta = datetime.timedelta(hours=latest_time.hour, minutes=latest_time.minute)\n",
    "        number_slots_minus_one = int((latest_time_as_delta - earliest_time_as_delta) / datetime.timedelta(minutes=30))\n",
    "\n",
    "        drawn_slot = seeded_random.randint(0, number_slots_minus_one)\n",
    "        vehicle_arrives_at_time_as_delta = earliest_time_as_delta + datetime.timedelta(hours=0.5 * drawn_slot)\n",
    "        vehicle_arrives_at_time = (datetime.datetime.min + vehicle_arrives_at_time_as_delta).time()\n",
    "        logger.info(f\"Add train '{train_vehicle_name}' to database\")\n",
    "        port_call_manager.add_large_scheduled_vehicle(\n",
    "            vehicle_type=ModeOfTransport.train,\n",
    "            service_name=train_vehicle_name,\n",
    "            vehicle_arrives_at=vessel_arrives_at_as_datetime_type.date(),\n",
    "            vehicle_arrives_at_time=vehicle_arrives_at_time,\n",
    "            average_vehicle_capacity=capacity,\n",
    "            average_moved_capacity=capacity,\n",
    "            vehicle_arrives_every_k_days=7\n",
    "        )\n",
    "\n",
    "        return container_flow_generation_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb78a1d-192a-473c-8cd6-1e5b14c03e74",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this scenario, we move traffic away from feeders to deep sea vessels\n",
    "\n",
    "container_flow_generation_manager = initialize_conflowgen(\"1a\")\n",
    "\n",
    "diff = 0.1\n",
    "\n",
    "mode_of_transport_distribution_1a = {\n",
    "    ModeOfTransport.truck: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6) - diff,\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6) + diff\n",
    "    },\n",
    "    ModeOfTransport.train: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6) - diff,\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6) + diff\n",
    "    },\n",
    "    ModeOfTransport.barge: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6) - diff,\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6) + diff\n",
    "    },\n",
    "    ModeOfTransport.feeder: {\n",
    "        ModeOfTransport.truck: 0.8 / (0.8 + 1.9) * 0.502,\n",
    "        ModeOfTransport.train: 0.8 / (0.8 + 1.9) * 0.47,\n",
    "        ModeOfTransport.barge: 0.8 / (0.8 + 1.9) * 0.0028,\n",
    "        ModeOfTransport.feeder: 0,\n",
    "        ModeOfTransport.deep_sea_vessel: 1.9 / (0.8 + 1.9)\n",
    "    },\n",
    "    ModeOfTransport.deep_sea_vessel: {\n",
    "        ModeOfTransport.truck: 4.6 / (4.6 + 1.9) * 0.502,\n",
    "        ModeOfTransport.train: 4.6 / (4.6 + 1.9) * 0.47,\n",
    "        ModeOfTransport.barge: 4.6 / (4.6 + 1.9) * 0.0028,\n",
    "        ModeOfTransport.feeder: 1.9 / (4.6 + 1.9),\n",
    "        ModeOfTransport.deep_sea_vessel: 0\n",
    "    }\n",
    "}\n",
    "\n",
    "ModeOfTransportDistributionManager().set_mode_of_transport_distributions(mode_of_transport_distribution_1a)\n",
    "\n",
    "container_flow_generation_manager.generate()\n",
    "export_container_flow_manager = ExportContainerFlowManager()\n",
    "folder_data_visual_1a = \"demo-DEHAM-visual-1a-0-1--\" + str(datetime.datetime.now()).replace(\":\", \"-\").replace(\" \", \"--\").split(\".\")[0]\n",
    "export_container_flow_manager.export(\n",
    "    folder_name=folder_data_visual_1a,\n",
    "    file_format=ExportFileFormat.csv\n",
    ")\n",
    "\n",
    "database_chooser.close_current_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a52c0-cd90-42d7-9d76-d13246feccbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this scenario, we keep things as they are\n",
    "\n",
    "container_flow_generation_manager = initialize_conflowgen(\"1b\")\n",
    "\n",
    "mode_of_transport_distribution_1b = {\n",
    "    ModeOfTransport.truck: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6),\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6)\n",
    "    },\n",
    "    ModeOfTransport.train: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6),\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6)\n",
    "    },\n",
    "    ModeOfTransport.barge: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6),\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6)\n",
    "    },\n",
    "    ModeOfTransport.feeder: {\n",
    "        ModeOfTransport.truck: 0.8 / (0.8 + 1.9) * 0.502,\n",
    "        ModeOfTransport.train: 0.8 / (0.8 + 1.9) * 0.47,\n",
    "        ModeOfTransport.barge: 0.8 / (0.8 + 1.9) * 0.0028,\n",
    "        ModeOfTransport.feeder: 0,\n",
    "        ModeOfTransport.deep_sea_vessel: 1.9 / (0.8 + 1.9)\n",
    "    },\n",
    "    ModeOfTransport.deep_sea_vessel: {\n",
    "        ModeOfTransport.truck: 4.6 / (4.6 + 1.9) * 0.502,\n",
    "        ModeOfTransport.train: 4.6 / (4.6 + 1.9) * 0.47,\n",
    "        ModeOfTransport.barge: 4.6 / (4.6 + 1.9) * 0.0028,\n",
    "        ModeOfTransport.feeder: 1.9 / (4.6 + 1.9),\n",
    "        ModeOfTransport.deep_sea_vessel: 0\n",
    "    }\n",
    "}\n",
    "\n",
    "ModeOfTransportDistributionManager().set_mode_of_transport_distributions(mode_of_transport_distribution_1b)\n",
    "\n",
    "container_flow_generation_manager.generate()\n",
    "export_container_flow_manager = ExportContainerFlowManager()\n",
    "folder_data_visual_1b = \"demo-DEHAM-visual-1b-0-1--\" + str(datetime.datetime.now()).replace(\":\", \"-\").replace(\" \", \"--\").split(\".\")[0]\n",
    "export_container_flow_manager.export(\n",
    "    folder_name=folder_data_visual_1b,\n",
    "    file_format=ExportFileFormat.csv\n",
    ")\n",
    "\n",
    "database_chooser.close_current_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd04e36-3547-4b6b-898e-9c1f8a3629f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "container_flow_generation_manager = initialize_conflowgen(\"1c\")\n",
    "\n",
    "# In this scenario, we move traffic away from deep sea vessels to feeders\n",
    "mode_of_transport_distribution_1c = {\n",
    "    ModeOfTransport.truck: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6) + diff,\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6) - diff\n",
    "    },\n",
    "    ModeOfTransport.train: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6) + diff,\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6) - diff\n",
    "    },\n",
    "    ModeOfTransport.barge: {\n",
    "        ModeOfTransport.truck: 0,\n",
    "        ModeOfTransport.train: 0,\n",
    "        ModeOfTransport.barge: 0,\n",
    "        ModeOfTransport.feeder: 0.8 / (0.8 + 4.6) + diff,\n",
    "        ModeOfTransport.deep_sea_vessel: 4.6 / (0.8 + 4.6) - diff\n",
    "    },\n",
    "    ModeOfTransport.feeder: {\n",
    "        ModeOfTransport.truck: 0.8 / (0.8 + 1.9) * 0.502,\n",
    "        ModeOfTransport.train: 0.8 / (0.8 + 1.9) * 0.47,\n",
    "        ModeOfTransport.barge: 0.8 / (0.8 + 1.9) * 0.0028,\n",
    "        ModeOfTransport.feeder: 0,\n",
    "        ModeOfTransport.deep_sea_vessel: 1.9 / (0.8 + 1.9)\n",
    "    },\n",
    "    ModeOfTransport.deep_sea_vessel: {\n",
    "        ModeOfTransport.truck: 4.6 / (4.6 + 1.9) * 0.502,\n",
    "        ModeOfTransport.train: 4.6 / (4.6 + 1.9) * 0.47,\n",
    "        ModeOfTransport.barge: 4.6 / (4.6 + 1.9) * 0.0028,\n",
    "        ModeOfTransport.feeder: 1.9 / (4.6 + 1.9),\n",
    "        ModeOfTransport.deep_sea_vessel: 0\n",
    "    }\n",
    "}\n",
    "\n",
    "ModeOfTransportDistributionManager().set_mode_of_transport_distributions(mode_of_transport_distribution_1c)\n",
    "\n",
    "container_flow_generation_manager.generate()\n",
    "export_container_flow_manager = ExportContainerFlowManager()\n",
    "folder_data_visual_1c = \"demo-DEHAM-visual-1c-0-1--\" + str(datetime.datetime.now()).replace(\":\", \"-\").replace(\" \", \"--\").split(\".\")[0]\n",
    "export_container_flow_manager.export(\n",
    "    folder_name=folder_data_visual_1c,\n",
    "    file_format=ExportFileFormat.csv\n",
    ")\n",
    "\n",
    "database_chooser.close_current_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490150f9-f799-4039-8576-27e9e8da4e02",
   "metadata": {},
   "source": [
    "## Prepare visuals\n",
    "\n",
    "Later we will convert SVG files to EMF files.\n",
    "While Microsoft does not support SVG files in its Office suite, EMF is one option how to include vector graphics into Word or PowerPoint.\n",
    "One way to convert from SVG to EMF is by using the open source software Inkscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe233d-c27d-4685-b617-b22a36021add",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    path_to_inkscape_executable = r\"C:\\Program Files\\Inkscape\\bin\\inkscape.exe\"\n",
    "else:\n",
    "    raise RuntimeException(\"Add your path to your inkscape executable here\")\n",
    "\n",
    "\n",
    "def convert_to_emf(input_file):\n",
    "    output_file = \"\".join(input_file.split(\".\")[0:-1]) + \".emf\"\n",
    "    !\"{path_to_inkscape_executable}\" \"{input_file}\" --export-filename \"{output_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f703f-923e-4026-ad1e-db706c519098",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248a63d-7299-4db9-b6d0-e5b8c3f4b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = os.path.abspath(\n",
    "    os.path.join(\n",
    "        os.path.dirname(conflowgen.__path__[0]),\n",
    "        \"conflowgen\",\n",
    "        \"data\",\n",
    "        \"exports\"\n",
    "    )\n",
    ")\n",
    "\n",
    "path_to_folder_data_visual_1a = os.path.join(\n",
    "    export_folder,\n",
    "    folder_data_visual_1a\n",
    ")\n",
    "\n",
    "path_to_folder_data_visual_1b = os.path.join(\n",
    "    export_folder,\n",
    "    folder_data_visual_1b\n",
    ")\n",
    "\n",
    "path_to_folder_data_visual_1c = os.path.join(\n",
    "    export_folder,\n",
    "    folder_data_visual_1c\n",
    ")\n",
    "\n",
    "print(\"Working with: \", (path_to_folder_data_visual_1a, path_to_folder_data_visual_1b, path_to_folder_data_visual_1c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bba6d9-c697-47b1-8cb6-ac7bc2c48f79",
   "metadata": {},
   "source": [
    "### Load containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b11c8-fca9-4b2d-854a-3438c0e92f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_containers(path_to_folder_data: str):\n",
    "\n",
    "    path_to_containers = os.path.join(\n",
    "        path_to_folder_data,\n",
    "        \"containers.csv\"\n",
    "    )\n",
    "    df_containers = pd.read_csv(path_to_containers, index_col=\"id\", dtype={\n",
    "        \"delivered_by_truck\": \"Int64\",\n",
    "        \"picked_up_by_truck\": \"Int64\",\n",
    "        \"delivered_by_large_scheduled_vehicle\": \"Int64\",\n",
    "        \"picked_up_by_large_scheduled_vehicle\": \"Int64\"\n",
    "    })\n",
    "    return df_containers\n",
    "\n",
    "\n",
    "df_containers_1a = load_containers(path_to_folder_data_visual_1a)\n",
    "df_containers_1b = load_containers(path_to_folder_data_visual_1b)\n",
    "df_containers_1c = load_containers(path_to_folder_data_visual_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928c273-6008-4f81-b550-c3dae18949ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_containers_1b.groupby(by=\"delivered_by_large_scheduled_vehicle\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530b578-8635-41c4-8ce0-07a4db7a2167",
   "metadata": {},
   "source": [
    "### Load vehicles adhering to a schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19012fa4-251a-422c-87f4-7100492f92a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scheduled_vehicle_file_paths(path_to_folder_data_visual: str):\n",
    "    path_to_deep_sea_vessels = os.path.join(\n",
    "        path_to_folder_data_visual,\n",
    "        \"deep_sea_vessels.csv\"\n",
    "    )\n",
    "\n",
    "    path_to_feeders = os.path.join(\n",
    "        path_to_folder_data_visual,\n",
    "        \"feeders.csv\"\n",
    "    )\n",
    "\n",
    "    path_to_barges = os.path.join(\n",
    "        path_to_folder_data_visual,\n",
    "        \"barges.csv\"\n",
    "    )\n",
    "\n",
    "    path_to_trains = os.path.join(\n",
    "        path_to_folder_data_visual,\n",
    "        \"trains.csv\"\n",
    "    )\n",
    "\n",
    "    scheduled_vehicle_file_paths = {\n",
    "        \"deep_sea_vessels\": path_to_deep_sea_vessels,\n",
    "        \"feeders\": path_to_feeders,\n",
    "        \"barges\": path_to_barges,\n",
    "        \"trains\": path_to_trains\n",
    "    }\n",
    "\n",
    "    for name, path in scheduled_vehicle_file_paths.items():\n",
    "        print(\"Check file exists for vehicle \" + name + f\" in folder {path_to_folder_data_visual}.\")\n",
    "        assert os.path.isfile(path)\n",
    "\n",
    "    return scheduled_vehicle_file_paths\n",
    "\n",
    "\n",
    "scheduled_vehicle_file_paths_1a = get_scheduled_vehicle_file_paths(path_to_folder_data_visual_1a)\n",
    "scheduled_vehicle_file_paths_1b = get_scheduled_vehicle_file_paths(path_to_folder_data_visual_1b)\n",
    "scheduled_vehicle_file_paths_1c = get_scheduled_vehicle_file_paths(path_to_folder_data_visual_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03ceca-9ea3-4c72-8901-3b88ac5c335b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for scheduled_vehicle_file_paths in (scheduled_vehicle_file_paths_1a, scheduled_vehicle_file_paths_1b, scheduled_vehicle_file_paths_1c):\n",
    "    for name, path in list(scheduled_vehicle_file_paths.items()):\n",
    "        print(\"Check file size for vehicle \" + name + f\" in folder {path}\")\n",
    "        size_in_bytes = os.path.getsize(path)\n",
    "        if size_in_bytes <= 4:\n",
    "            print(\"    This file is empty, ignoring it in the analysis from now on\")\n",
    "            del scheduled_vehicle_file_paths_1b[name]\n",
    "        else:\n",
    "            print(\"Everything is ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a404074-48d0-43ab-ace5-e1d0afd8ccf5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scheduled_vehicle_dfs(scheduled_vehicle_file_paths, figure_name: str):\n",
    "    scheduled_vehicle_dfs = {\n",
    "        name: pd.read_csv(path, index_col=0, parse_dates=[\"scheduled_arrival\"])\n",
    "        for name, path in scheduled_vehicle_file_paths.items()\n",
    "    }\n",
    "\n",
    "    for name, df in scheduled_vehicle_dfs.items():\n",
    "        display(Markdown(\"#### \" + name.replace(\"_\", \" \").capitalize() + \" \" + figure_name))\n",
    "        scheduled_vehicle_dfs[name][\"vehicle_type\"] = name\n",
    "        display(scheduled_vehicle_dfs[name].sort_values(by=\"scheduled_arrival\"))\n",
    "    return scheduled_vehicle_dfs\n",
    "\n",
    "\n",
    "scheduled_vehicle_dfs_1a = get_scheduled_vehicle_dfs(scheduled_vehicle_file_paths_1a, \"1a\")\n",
    "scheduled_vehicle_dfs_1b = get_scheduled_vehicle_dfs(scheduled_vehicle_file_paths_1b, \"1b\")\n",
    "scheduled_vehicle_dfs_1c = get_scheduled_vehicle_dfs(scheduled_vehicle_file_paths_1c, \"1c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551a3cf-5400-427d-952b-45c31c43cea5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_df_large_scheduled_vehicle(scheduled_vehicle_dfs):\n",
    "    df_large_scheduled_vehicle = pd.concat(\n",
    "        scheduled_vehicle_dfs.values()\n",
    "    )\n",
    "    df_large_scheduled_vehicle.sort_index(inplace=True)\n",
    "    df_large_scheduled_vehicle.info()\n",
    "    return df_large_scheduled_vehicle\n",
    "\n",
    "\n",
    "df_large_scheduled_vehicle_1a = prepare_df_large_scheduled_vehicle(scheduled_vehicle_dfs_1a)\n",
    "df_large_scheduled_vehicle_1b = prepare_df_large_scheduled_vehicle(scheduled_vehicle_dfs_1b)\n",
    "df_large_scheduled_vehicle_1c = prepare_df_large_scheduled_vehicle(scheduled_vehicle_dfs_1c)\n",
    "\n",
    "df_large_scheduled_vehicle_1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffcb93-6308-4282-be77-da2965f7584c",
   "metadata": {},
   "source": [
    "### Load trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a9923-a0c7-4283-8153-a12592e53a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_trucks_1a = os.path.join(\n",
    "    path_to_folder_data_visual_1a,\n",
    "    \"trucks.csv\"\n",
    ")\n",
    "assert os.path.isfile(path_to_trucks_1a)\n",
    "path_to_trucks_1b = os.path.join(\n",
    "    path_to_folder_data_visual_1b,\n",
    "    \"trucks.csv\"\n",
    ")\n",
    "assert os.path.isfile(path_to_trucks_1b)\n",
    "path_to_trucks_1c = os.path.join(\n",
    "    path_to_folder_data_visual_1c,\n",
    "    \"trucks.csv\"\n",
    ")\n",
    "assert os.path.isfile(path_to_trucks_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c06605-800c-4484-a3e8-28c1b5bbc466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trucks(path: str):\n",
    "    return pd.read_csv(\n",
    "        path_to_trucks_1b, index_col=0,\n",
    "        parse_dates=[\n",
    "            # Pickup\n",
    "            \"planned_container_pickup_time_prior_berthing\",\n",
    "            \"realized_container_pickup_time\",\n",
    "\n",
    "            # Delivery\n",
    "            \"planned_container_delivery_time_at_window_start\",\n",
    "            \"realized_container_delivery_time\"\n",
    "        ])\n",
    "\n",
    "\n",
    "df_truck_1a = load_trucks(path_to_trucks_1a)\n",
    "df_truck_1b = load_trucks(path_to_trucks_1b)\n",
    "df_truck_1c = load_trucks(path_to_trucks_1c)\n",
    "\n",
    "df_truck_1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407b9b7-08f8-4340-9b4c-97f0c9b8ad87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot arrival distribution over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a416b8-d117-44ff-92c2-e50943c42695",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aaccb5-52ff-4255-a171-91aa41ecb1ce",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y, z = [], [], []\n",
    "y_axis = []\n",
    "\n",
    "y_scaling_factor = 2\n",
    "\n",
    "for i, (name, df) in enumerate(scheduled_vehicle_dfs_1b.items()):\n",
    "    y_axis.append((i/y_scaling_factor, name))\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"vehicle_type\"] == \"trains\":\n",
    "            continue\n",
    "        event = row[\"scheduled_arrival\"]\n",
    "        moved_capacity = row[\"moved_capacity\"]\n",
    "        x.append(event)\n",
    "        y.append(i / y_scaling_factor)\n",
    "        z.append(moved_capacity)\n",
    "\n",
    "\n",
    "arrivals_and_capacity_1b = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
    "display(arrivals_and_capacity_1b)\n",
    "arrivals_and_capacity_1b.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422682a-5207-4195-b6cd-d8201a7756bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_deliveries_by_truck_1b = df_truck_1b.groupby(\n",
    "    pd.Grouper(key='realized_container_delivery_time', freq='H')\n",
    ").count().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d404c89-ca85-4ba1-8188-213aa0b36d9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create figure that shows the arrivals of different vehicles next to each other.\n",
    "This creates a first impression of the ramp-up and ramp-down phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43836e-6951-4b24-8a86-50e46cbfdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[2, 1])\n",
    "\n",
    "ax1 = plt.subplot(gs[0])  # the upper subplot\n",
    "\n",
    "ax1.plot(container_deliveries_by_truck_1b[\"delivers_container\"], color=\"k\", linewidth=.7)\n",
    "ax1.set_ylabel(\"Truck arrivals per hour\")\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_xlim([pd.Timestamp(\"2021-06-27\"), pd.Timestamp(pd.Timestamp(\"2021-08-02\"))])\n",
    "\n",
    "ax2 = plt.subplot(gs[1], sharex=ax1)  # the lower subplot\n",
    "\n",
    "color_capacity_dots = 'dimgray'\n",
    "\n",
    "# x-axis: time, y-axis: dummy variable for lower or upper row\n",
    "moved_teu_scale_factor = 10\n",
    "scatterplot = ax2.scatter(\n",
    "    x, y,\n",
    "    s=np.array(z)/moved_teu_scale_factor,\n",
    "    marker=\"o\", color=color_capacity_dots, edgecolor=\"k\"\n",
    ")\n",
    "\n",
    "myFmt = mdates.DateFormatter('%d.%m.')\n",
    "ax1.xaxis.set_major_formatter(myFmt)\n",
    "ax2.xaxis.set_major_formatter(myFmt)\n",
    "ax2.set_yticks([0.0, .5])\n",
    "ax2.set_yticklabels([\"Deep sea\\nvessels\", \"Feeders\"])\n",
    "ax2.set_ylim([-0.3, 0.7])\n",
    "\n",
    "handles, labels = scatterplot.legend_elements(prop=\"sizes\", num=4)\n",
    "adjusted_labels = []\n",
    "for handle, label in zip(handles, labels):\n",
    "    label_digits_only = \"\".join([c for c in label if c in string.digits])\n",
    "    number = int(label_digits_only)\n",
    "    number *= moved_teu_scale_factor\n",
    "    formatted_label = \"$\\\\mathdefault{\" + str(number) + \"}$\"\n",
    "    adjusted_labels.append(formatted_label)\n",
    "    handle.set_markerfacecolor(color_capacity_dots)\n",
    "\n",
    "ax2.legend(\n",
    "    handles,\n",
    "    adjusted_labels,\n",
    "    borderpad=1.2,\n",
    "    labelspacing=1.2,\n",
    "    loc=(1.02, 0),\n",
    "    title=\"Moved TEU\"\n",
    ")\n",
    "\n",
    "# Hide first date (it is in June) as it distorts the plot\n",
    "ax2.set_xticks(ax2.get_xticks()[1:])\n",
    "\n",
    "# just comment this in in case you want to save the figure\n",
    "plt.savefig(\"relationship_truck_deliveries_and_vessel_departures.svg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc773a-f70a-4246-bce7-1838b3ad3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just comment this in in case you want to convert the figure from svg to emf\n",
    "convert_to_emf(\"relationship_truck_deliveries_and_vessel_departures.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36515f94-8912-4a6e-ac12-3d9e1e9d1241",
   "metadata": {},
   "source": [
    "## Plot capacity for inbound and outbound movements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fe532-a0c5-4d13-9c98-4567a8360ae2",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba37544-0002-4bba-a70d-b111fcb70586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delivery_and_pickup(df_containers: pd.DataFrame, df_large_scheduled_vehicle: pd.DataFrame):\n",
    "    vehicle_to_teu_to_deliver = {}\n",
    "    vehicle_to_teu_to_pickup = {}\n",
    "\n",
    "    for i, container in df_containers.iterrows():\n",
    "        teu = container[\"length\"] / 20\n",
    "        assert 1 <= teu <= 2.5\n",
    "\n",
    "        if container[\"delivered_by\"] != \"truck\":\n",
    "            vehicle = container[\"delivered_by_large_scheduled_vehicle\"]\n",
    "            if vehicle not in vehicle_to_teu_to_deliver.keys():\n",
    "                vehicle_to_teu_to_deliver[vehicle] = 0\n",
    "            vehicle_to_teu_to_deliver[vehicle] += teu\n",
    "\n",
    "        if container[\"picked_up_by\"] != \"truck\":\n",
    "            vehicle = container[\"picked_up_by_large_scheduled_vehicle\"]\n",
    "            if vehicle not in vehicle_to_teu_to_pickup.keys():\n",
    "                vehicle_to_teu_to_pickup[vehicle] = 0\n",
    "            vehicle_to_teu_to_pickup[vehicle] += teu\n",
    "\n",
    "    s_delivery = pd.Series(vehicle_to_teu_to_deliver)\n",
    "    s_pickup = pd.Series(vehicle_to_teu_to_pickup)\n",
    "    df_large_scheduled_vehicle[\"capacity_delivery\"] = s_delivery\n",
    "    df_large_scheduled_vehicle[\"capacity_pickup\"] = s_pickup\n",
    "\n",
    "\n",
    "add_delivery_and_pickup(df_containers_1a, df_large_scheduled_vehicle_1a)\n",
    "add_delivery_and_pickup(df_containers_1b, df_large_scheduled_vehicle_1b)\n",
    "add_delivery_and_pickup(df_containers_1c, df_large_scheduled_vehicle_1c)\n",
    "df_large_scheduled_vehicle_1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f774ce-d76f-4444-b283-5a06718b67bf",
   "metadata": {},
   "source": [
    "Compare 1a, 1b, and 1c with each other.\n",
    "This is an example of how parameters need to be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa97ab-b23a-4a66-93bf-cd6c05000fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=3,\n",
    "    figsize=(10, 3.3),\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "colors = {\n",
    "    'feeders': 'navy',\n",
    "    'deep_sea_vessels': 'olive'\n",
    "}\n",
    "\n",
    "for title, ax, df_large_scheduled_vehicle in zip(\"abc\", axs, (\n",
    "    df_large_scheduled_vehicle_1a,\n",
    "    df_large_scheduled_vehicle_1b,\n",
    "    df_large_scheduled_vehicle_1c\n",
    ")):\n",
    "    df_large_scheduled_vehicle = df_large_scheduled_vehicle[\n",
    "        ~df_large_scheduled_vehicle['vehicle_type'].isin(\n",
    "            [\n",
    "                \"trains\",\n",
    "                \"barges\"\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    ax.scatter(\n",
    "        df_large_scheduled_vehicle['capacity_delivery'],\n",
    "        df_large_scheduled_vehicle['capacity_pickup'],\n",
    "        c=list(df_large_scheduled_vehicle['vehicle_type'].map(colors)),\n",
    "        marker=\".\"\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.axline((0, 0), slope=1.2, color='dimgray', label='Ratio of 1:1.2 (20% buffer)')\n",
    "    ax.axline((0, 0), slope=1,   color='lightgray', label='Ratio of 1:1')\n",
    "    ax.set_xlim([0, 3500])\n",
    "    ax.set_ylim([0, 3500])\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(color='lightgray', linestyle=':', linewidth=.5)\n",
    "\n",
    "plt.setp(axs[:], xlabel=\"TEU delivered by vessel\")\n",
    "axs[0].set_ylabel(\"TEU picked up by vessel\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "for vehicle_type, color in colors.items():\n",
    "    vehicle_type_legend_name = vehicle_type.replace(\"_\", \" \").capitalize()\n",
    "    patch = plt.Line2D([], [], color=color, marker=\"o\", linewidth=0, label=vehicle_type_legend_name)\n",
    "    handles.append(patch)\n",
    "\n",
    "plt.legend(\n",
    "    handles=handles,\n",
    "    loc='lower left',\n",
    "    bbox_to_anchor=(-2.2, -0.4),\n",
    "    fancybox=True,\n",
    "    ncol=4\n",
    ")\n",
    "\n",
    "# just comment this in in case you want to save the figure\n",
    "plt.savefig(\"ratio_delivered_and_picked_up_containers_comparison.svg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fff3d-1533-4d24-ae82-a996e849c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just comment this in in case you want to convert the figure from svg to emf\n",
    "convert_to_emf(\"ratio_delivered_and_picked_up_containers_comparison.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dbd00-3fa3-41ac-8273-19796f4130ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
